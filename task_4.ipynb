{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №4 (курс \"Python 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выполнил: <font color='red'>Каленюк Аким Александрович</font>\n",
    "\n",
    "### Тема: Web-сервер для обучения и использования ML-моделей\n",
    "\n",
    "#### Преподаватели: Роман Ищенко (roman.ischenko@gmail.com) и Илья Склонин\n",
    "\n",
    "**Дедлайн**: 18.01.2026\n",
    "\n",
    "**Среда выполнения**: Jupyter Notebook (Python 3.9+)\n",
    "\n",
    "#### Правила:\n",
    "\n",
    "Результаты выполнения задания:\n",
    "\n",
    "- архив со скриптами и файлами Dockerfile, который 1-2 команды позволяет развернуть сервер, решающий поставленные в задании задачи\n",
    "- Jupyter Notebook, где __весь код__ из скриптов дублируется (1 ячейка - 1 скрипт) с комментарием, содержащим информацию о том, из какого файла взят код и что верхнеуровнево этот код делает\n",
    "\n",
    "__Максимальное число баллов за задание - 35__.\n",
    "\n",
    "Готовое задание отправляется на почту преподавателя.\n",
    "\n",
    "Задание выполняется самостоятельно. Если какие-то студенты будут уличены в списывании, все они автоматически получат за эту работу 0 баллов. Если вы нашли в Интернете какой-то специфичный код, который собираетесь заимствовать, обязательно укажите это в задании - наверняка вы не единственный, кто найдёт и использует эту информацию.\n",
    "\n",
    "Удалять фрагменты формулировок заданий запрещается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постановка задачи:\n",
    "\n",
    "**Серверная часть (22 балла):**\n",
    "\n",
    "- В данной работе нужно написать многозадачный веб-сервер для обучения и инференса ML моделей. На старте сервер получает на вход (через .env) конфиг, в котором должны быть указаны 3 параметра: путь к директории для сохранения моделей внутри контейнера сервера, число ядер, доступных для обучения и максимальное число моделей, которые могут быть одновременно загружены для инференса.\n",
    "\n",
    "\n",
    "- Сервер должен реализовывать следующие методы:\n",
    "    - `fit(X, y, config)` - обучить модель и сохранить на диск по указанным именем\n",
    "    - `predict(y, config)` - предсказать с помощью обученной и загруженной модели по её имени\n",
    "    - `load(config)` - загрузить обученную модель по её имени в режим инференса\n",
    "    - `unload(config)` - выгрузить загруженную модель по её имени\n",
    "    - `remove(config)` - удалить обученную модель с диска по её имени\n",
    "    - `remove_all()` - удалить все обученные модели с диска\n",
    "\n",
    "\n",
    "- Содержимое конфигов и форматы данных предлагается продумать и реализовать самостоятельно\n",
    "- Сервер должен иметь счётчик активных процессов. Максимальное число активных процессов соответствует числу ядер, переданному в конфиге при старте сервиса. Каждое обучение модели запускается в отдельном процессе и до своего завершения потребляет этот процесс. Один процесс всегда остаётся для сервера, в нём же загружаются и работают на инференс обученные модели\n",
    "- Сервер должен корректно обрабатывать все граничные случаи (запуск обучения без свободных ядер, запуск инфренса свыше лимита, запросы с несуществующими именами моделей, запросы с дублирующимися именами моделей)\n",
    "- В реализации должны поддерживаться не менее трёх дискриминативных моделей (т.е. принимающих на вход объекты и метки при обучении и предсказывающих метки для новых объектов)\n",
    "- Сервер должен быть реализован на FastAPI\n",
    "- Проект разворачивается с помощью выбранной библиотеки управления виртуальными окружениями и технологии контейнеризации Docker\n",
    "\n",
    "**Клиентская часть (13 баллов):**\n",
    "\n",
    "- Клиентская часть должна демонстрировать работу с реализованным сервером с помощью библиотек requests и aiohttp. Она может быть реализована непосредственно в Jupyter Notebook, с описанием ожидаемого действия, или в отдельном(-ых) скрипте(-ах), с дублированием в Jupyter Notebook (тогда работоспособность в ноутбуке не требуется). Далее описываются отдельные функции:\n",
    "- Код вызова последовательного вызова обучения как минимум двух (N) различных моделей с таким набором данных и параметрами, чтобы обучение одной модели длилось не менее 60 секунд.\n",
    "- Код вызова асинхронного вызова обучения как минимум двух различных моделей с демонстрацией, что работа выполняется в два (в N) раза быстрее\n",
    "- Асинхронный вызов нескольких предсказаний\n",
    "- Код демонстрации остальных функций сервера (загрузка, выгрузка, удаление)\n",
    "- Должны обрабатываться ошибки и исключения, возвращаемые сервером\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поработаем с сервером"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "def check_server_status():\n",
    "    \"\"\"Проверка статуса сервера\"\"\"\n",
    "    response = requests.get(f\"{BASE_URL}/\")\n",
    "    print(\"Статус сервера:\", response.json())\n",
    "\n",
    "def get_server_status():\n",
    "    \"\"\"Получение подробного статуса\"\"\"\n",
    "    response = requests.get(f\"{BASE_URL}/status\")\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последовательное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "n_features = 100\n",
    "\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = np.random.randint(0, 2, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "        {\n",
    "            \"name\": \"model_logreg_large\",\n",
    "            \"type\": \"logreg\",\n",
    "            \"params\": {\"max_iter\": 5000, \"random_state\": 42}\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"model_rf_large\",\n",
    "            \"type\": \"rf\",\n",
    "            \"params\": {\"n_estimators\": 500, \"max_depth\": 20, \"random_state\": 42}\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение model_logreg_large...\n",
      "Запущено: Обучение модели 'model_logreg_large' запущено\n",
      "{'status': 'training', 'model_name': 'model_logreg_large'}\n",
      "{'status': 'success', 'model_name': 'model_logreg_large', 'training_time': 0.0471346378326416}\n",
      "Обучение завершено за 0.05 секунд\n",
      "\n",
      "Обучение model_rf_large...\n",
      "Запущено: Обучение модели 'model_rf_large' запущено\n",
      "{'status': 'training', 'model_name': 'model_rf_large'}\n",
      "{'status': 'training', 'model_name': 'model_rf_large'}\n",
      "{'status': 'training', 'model_name': 'model_rf_large'}\n",
      "{'status': 'training', 'model_name': 'model_rf_large'}\n",
      "{'status': 'training', 'model_name': 'model_rf_large'}\n",
      "{'status': 'training', 'model_name': 'model_rf_large'}\n",
      "{'status': 'training', 'model_name': 'model_rf_large'}\n",
      "{'status': 'success', 'model_name': 'model_rf_large', 'training_time': 32.807024002075195}\n",
      "Обучение завершено за 32.81 секунд\n",
      "\n",
      "Общее время последовательного обучения: 41.34 секунд\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for model_info in models:\n",
    "    print(f\"\\nОбучение {model_info['name']}...\")\n",
    "    \n",
    "    fit_request = {\n",
    "        \"model_name\": model_info[\"name\"],\n",
    "        \"model_type\": model_info[\"type\"],\n",
    "        \"features\": X.tolist(),\n",
    "        \"labels\": y.tolist(),\n",
    "        \"params\": model_info[\"params\"]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/fit\",\n",
    "        json=fit_request,\n",
    "        headers={\"Content-Type\": \"application/json\"}\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Запущено: {response.json()['message']}\")\n",
    "        \n",
    "        while True:\n",
    "            status_response = requests.get(\n",
    "                f\"{BASE_URL}/fit/{model_info['name']}/status\"\n",
    "            )\n",
    "            status_data = status_response.json()\n",
    "            print(status_data)\n",
    "            if status_data['status'] == 'success':\n",
    "                training_time = status_data.get('training_time', 0)\n",
    "                print(f\"Обучение завершено за {training_time:.2f} секунд\")\n",
    "                break\n",
    "            elif status_data['status'] == 'error':\n",
    "                print(f\"Ошибка: {status_data}\")\n",
    "                break\n",
    "            else:\n",
    "                print(\".\", end=\"\", flush=True)\n",
    "                time.sleep(5)\n",
    "    else:\n",
    "        print(f\"Ошибка: {response.status_code} - {response.text}\")\n",
    "\n",
    "sequential_total_time = time.time() - start_time\n",
    "print(f\"\\nОбщее время последовательного обучения: {sequential_total_time:.2f} секунд\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Асинхронное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "n_features = 100\n",
    "\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = np.random.randint(0, 2, n_samples)\n",
    "\n",
    "# Модели для обучения\n",
    "models = [\n",
    "    {\n",
    "        \"name\": \"async_model_svm\",\n",
    "        \"type\": \"svm\",\n",
    "        \"params\": {\"kernel\": \"rbf\", \"random_state\": 42}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"async_model_rf\",\n",
    "        \"type\": \"rf\",\n",
    "        \"params\": {\"n_estimators\": 300, \"random_state\": 42}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def train_model_async(session, model_info):\n",
    "    \"\"\"Асинхронное обучение одной модели\"\"\"\n",
    "    fit_request = {\n",
    "        \"model_name\": model_info[\"name\"],\n",
    "        \"model_type\": model_info[\"type\"],\n",
    "        \"features\": X.tolist(),\n",
    "        \"labels\": y.tolist(),\n",
    "        \"params\": model_info[\"params\"]\n",
    "    }\n",
    "    \n",
    "    async with session.post(\n",
    "        f\"{BASE_URL}/fit\",\n",
    "        json=fit_request\n",
    "    ) as response:\n",
    "        if response.status == 200:\n",
    "            print(f\"Запущено обучение: {model_info['name']}\")\n",
    "            \n",
    "            while True:\n",
    "                async with session.get(\n",
    "                    f\"{BASE_URL}/fit/{model_info['name']}/status\"\n",
    "                ) as status_response:\n",
    "                    status_data = await status_response.json()\n",
    "                    \n",
    "                    if status_data['status'] == 'success':\n",
    "                        training_time = status_data.get('training_time', 0)\n",
    "                        print(f\"Модель {model_info['name']} обучена за {training_time:.2f}с\")\n",
    "                        return training_time\n",
    "                    elif status_data['status'] == 'error':\n",
    "                        print(f\"Ошибка при обучении {model_info['name']}: {status_data}\")\n",
    "                        return None\n",
    "                    else:\n",
    "                        await asyncio.sleep(5)\n",
    "        else:\n",
    "            print(f\"Ошибка запуска {model_info['name']}: {await response.text()}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запущено обучение: async_model_rf\n",
      "Запущено обучение: async_model_svm\n",
      "Модель async_model_svm обучена за 17.72с\n",
      "Модель async_model_rf обучена за 21.62с\n",
      "\n",
      "Общее время асинхронного обучения: 22.53 секунд\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "    \n",
    "async with aiohttp.ClientSession() as session:\n",
    "    tasks = [train_model_async(session, model_info) for model_info in models]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nОбщее время асинхронного обучения: {total_time:.2f} секунд\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Асинхронные предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель model_logreg_large загружена\n",
      "Модель model_rf_large загружена\n"
     ]
    }
   ],
   "source": [
    "models_to_load = [\"model_logreg_large\", \"model_rf_large\"]\n",
    "    \n",
    "for model_name in models_to_load:\n",
    "    load_request = {\"model_name\": model_name}\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/load\",\n",
    "        json=load_request\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Модель {model_name} загружена\")\n",
    "    elif \"already loaded\" not in response.text.lower():\n",
    "        print(f\"Предупреждение: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "n_predictions = 100\n",
    "n_features = 100\n",
    "\n",
    "X_test = np.random.randn(n_predictions, n_features).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def predict_async(session, model_name, data):\n",
    "    \"\"\"Асинхронное предсказание\"\"\"\n",
    "    predict_request = {\n",
    "        \"model_name\": model_name,\n",
    "        \"features\": data\n",
    "    }\n",
    "    \n",
    "    async with session.post(\n",
    "        f\"{BASE_URL}/predict\",\n",
    "        json=predict_request\n",
    "    ) as response:\n",
    "        if response.status == 200:\n",
    "            result = await response.json()\n",
    "            return {\n",
    "                \"model\": model_name,\n",
    "                \"predictions\": result[\"predictions\"][:5],  \n",
    "                \"status\": \"success\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"model\": model_name,\n",
    "                \"error\": await response.text(),\n",
    "                \"status\": \"error\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Выполнено 10 асинхронных предсказаний\n",
      "Общее время: 0.31 секунд\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "    \n",
    "async with aiohttp.ClientSession() as session:\n",
    "    tasks = []\n",
    "    for i in range(10):  \n",
    "        model_name = models_to_load[i % len(models_to_load)]\n",
    "        task = predict_async(session, model_name, X_test)\n",
    "        tasks.append(task)\n",
    "    \n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nВыполнено {len(results)} асинхронных предсказаний\")\n",
    "print(f\"Общее время: {total_time:.2f} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результат 1:\n",
      "  Модель: model_logreg_large\n",
      "  Пример предсказаний: [0, 0, 0, 0, 1]\n",
      "\n",
      "Результат 2:\n",
      "  Модель: model_rf_large\n",
      "  Пример предсказаний: [0, 1, 1, 1, 1]\n",
      "\n",
      "Результат 3:\n",
      "  Модель: model_logreg_large\n",
      "  Пример предсказаний: [0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "for i, result in enumerate(results[:3]):\n",
    "    print(f\"\\nРезультат {i+1}:\")\n",
    "    print(f\"  Модель: {result['model']}\")\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"  Пример предсказаний: {result['predictions']}\")\n",
    "    else:\n",
    "        print(f\"  Ошибка: {result.get('error', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Остальные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Список моделей:\n",
      "   Всего моделей: 4\n",
      "   - model_rf_large (загружена: True)\n",
      "   - async_model_rf (загружена: False)\n",
      "   - model_logreg_large (загружена: True)\n",
      "   - async_model_svm (загружена: False)\n",
      "\n",
      "2. Загрузка модели:\n",
      "   Результат: Модель 'model_logreg_large' загружена в память\n",
      "   Загружено моделей: 2\n",
      "\n",
      "3. Выгрузка модели:\n",
      "   Результат: Модель 'model_logreg_large' выгружена из памяти\n",
      "\n",
      "4. Удаление модели:\n",
      "   Результат: Модель 'async_model_svm' удалена с диска\n"
     ]
    }
   ],
   "source": [
    "print(\"1. Список моделей:\")\n",
    "response = requests.get(f\"{BASE_URL}/models\")\n",
    "if response.status_code == 200:\n",
    "    models = response.json()\n",
    "    print(f\"   Всего моделей: {models['count']}\")\n",
    "    for model in models['models']:\n",
    "        print(f\"   - {model['name']} (загружена: {model['loaded']})\")\n",
    "\n",
    "print(\"\\n2. Загрузка модели:\")\n",
    "load_request = {\"model_name\": \"model_logreg_large\"}\n",
    "response = requests.post(f\"{BASE_URL}/load\", json=load_request)\n",
    "print(f\"   Результат: {response.json()['message']}\")\n",
    "\n",
    "status = get_server_status()\n",
    "print(f\"   Загружено моделей: {status['loaded_models']}\")\n",
    "\n",
    "print(\"\\n3. Выгрузка модели:\")\n",
    "unload_request = {\"model_name\": \"model_logreg_large\"}\n",
    "response = requests.post(f\"{BASE_URL}/unload\", json=unload_request)\n",
    "print(f\"   Результат: {response.json()['message']}\")\n",
    "\n",
    "print(\"\\n4. Удаление модели:\")\n",
    "remove_request = {\"model_name\": \"async_model_svm\"}\n",
    "response = requests.delete(f\"{BASE_URL}/remove\", json=remove_request)\n",
    "print(f\"   Результат: {response.json()['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Обучение с существующим именем:\n",
      "   Код: 400\n",
      "   Ответ: {'detail': \"Модель с именем 'model_logreg_large' уже существует\"}\n",
      "\n",
      "2. Предсказание с несуществующей моделью:\n",
      "   Код: 404\n",
      "   Ответ: {'detail': \"Модель 'non_existent_model' не найдена\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"1. Обучение с существующим именем:\")\n",
    "fit_request = {\n",
    "    \"model_name\": \"model_logreg_large\",\n",
    "    \"model_type\": \"logreg\",\n",
    "    \"features\": [[1, 2], [3, 4]],\n",
    "    \"labels\": [0, 1]\n",
    "}\n",
    "response = requests.post(f\"{BASE_URL}/fit\", json=fit_request)\n",
    "print(f\"   Код: {response.status_code}\")\n",
    "print(f\"   Ответ: {response.json()}\")\n",
    "\n",
    "print(\"\\n2. Предсказание с несуществующей моделью:\")\n",
    "predict_request = {\n",
    "    \"model_name\": \"non_existent_model\",\n",
    "    \"features\": [[1, 2], [3, 4]]\n",
    "}\n",
    "response = requests.post(f\"{BASE_URL}/predict\", json=predict_request)\n",
    "print(f\"   Код: {response.status_code}\")\n",
    "print(f\"   Ответ: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание скриптов\n",
    "## app/config.py\n",
    "\n",
    "Что делает этот код:\n",
    "\n",
    "* Определяет настройки приложения через класс Settings, наследующийся от BaseSettings из pydantic-settings\n",
    "* Загружает конфигурацию из переменных окружения или файла .env\n",
    "* Содержит параметры: директория для моделей, количество CPU ядер, максимальное число загруженных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic_settings import BaseSettings\n",
    "from typing import Optional\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    \"\"\"Настройки приложения из переменных окружения\"\"\"\n",
    "    models_dir: str = \"./saved_models\"\n",
    "    cpu_cores: int = 4\n",
    "    max_loaded_models: int = 3\n",
    "    \n",
    "    class Config:\n",
    "        env_file = \".env\"\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## app/schemas.py\n",
    "\n",
    "* Определяет Pydantic-схемы для валидации входных данных и формирования ответов API\n",
    "* FitRequest: структура запроса для обучения модели\n",
    "* PredictRequest: структура запроса для предсказаний\n",
    "* ModelConfig: базовая конфигурация модели для операций загрузки/выгрузки\n",
    "* Ответные схемы (FitResponse, PredictResponse, StatusResponse) для стандартизации ответов сервера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any\n",
    "import numpy as np\n",
    "\n",
    "class FitRequest(BaseModel):\n",
    "    \"\"\"Схема для запроса обучения модели\"\"\"\n",
    "    model_name: str = Field(..., description=\"Название модели\")\n",
    "    model_type: str = Field(..., description=\"Тип модели (logreg, rf, svm)\")\n",
    "    features: List[List[float]] = Field(..., description=\"Признаки\")\n",
    "    labels: List[int] = Field(..., description=\"Метки\")\n",
    "    params: Optional[Dict[str, Any]] = Field(default={}, description=\"Параметры модели\")\n",
    "    \n",
    "    model_config = {\n",
    "        \"protected_namespaces\": ()\n",
    "    }\n",
    "\n",
    "class PredictRequest(BaseModel):\n",
    "    \"\"\"Схема для запроса предсказания\"\"\"\n",
    "    model_name: str = Field(..., description=\"Название модели\")\n",
    "    features: List[List[float]] = Field(..., description=\"Признаки для предсказания\")\n",
    "    \n",
    "    model_config = {\n",
    "        \"protected_namespaces\": ()\n",
    "    }\n",
    "\n",
    "class ModelConfig(BaseModel):\n",
    "    \"\"\"Схема для операций с моделями\"\"\"\n",
    "    model_name: str = Field(..., description=\"Название модели\")\n",
    "    \n",
    "    model_config = {\n",
    "        \"protected_namespaces\": ()\n",
    "    }\n",
    "\n",
    "class FitResponse(BaseModel):\n",
    "    \"\"\"Ответ на обучение модели\"\"\"\n",
    "    status: str\n",
    "    model_name: str\n",
    "    message: str\n",
    "    training_time: Optional[float] = None\n",
    "\n",
    "class PredictResponse(BaseModel):\n",
    "    \"\"\"Ответ на предсказание\"\"\"\n",
    "    status: str\n",
    "    predictions: List[int]\n",
    "    probabilities: Optional[List[List[float]]] = None\n",
    "\n",
    "class StatusResponse(BaseModel):\n",
    "    \"\"\"Общий ответ\"\"\"\n",
    "    status: str\n",
    "    message: str\n",
    "    details: Optional[Dict[str, Any]] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## app/model_manager.py\n",
    "\n",
    "* Реализует класс ModelManager для управления ML-моделями\n",
    "* Поддерживает три типа моделей: Logistic Regression, Random Forest, SVM\n",
    "* Обеспечивает обучение, сохранение, загрузку, выгрузку и удаление моделей\n",
    "* Управляет кэшированием загруженных моделей в памяти\n",
    "* Обрабатывает масштабирование признаков для SVM\n",
    "* Предоставляет методы для предсказаний и управления жизненным циклом моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from typing import Dict, Any, Tuple\n",
    "import time\n",
    "\n",
    "class ModelManager:\n",
    "    \"\"\"Менеджер для работы с ML моделями\"\"\"\n",
    "    \n",
    "    def __init__(self, models_dir: str):\n",
    "        self.models_dir = models_dir\n",
    "        os.makedirs(models_dir, exist_ok=True)\n",
    "        \n",
    "        self.model_types = {\n",
    "            'logreg': LogisticRegression,\n",
    "            'rf': RandomForestClassifier,\n",
    "            'svm': SVC\n",
    "        }\n",
    "        \n",
    "        self.loaded_models: Dict[str, Any] = {}\n",
    "        self.scalers: Dict[str, StandardScaler] = {}\n",
    "        \n",
    "        self.default_params = {\n",
    "            'logreg': {'max_iter': 1000, 'random_state': 42},\n",
    "            'rf': {'n_estimators': 100, 'random_state': 42},\n",
    "            'svm': {'kernel': 'rbf', 'random_state': 42, 'probability': True}\n",
    "        }\n",
    "    \n",
    "    def create_model(self, model_type: str, params: Dict[str, Any]) -> Any:\n",
    "        \"\"\"Создание модели по типу и параметрам\"\"\"\n",
    "        if model_type not in self.model_types:\n",
    "            raise ValueError(f\"Неизвестный тип модели: {model_type}\")\n",
    "        \n",
    "        default = self.default_params.get(model_type, {})\n",
    "        merged_params = {**default, **params}\n",
    "        \n",
    "        return self.model_types[model_type](**merged_params)\n",
    "    \n",
    "    def train_model(self, model_name: str, model_type: str, \n",
    "                   X: np.ndarray, y: np.ndarray, params: Dict[str, Any]) -> float:\n",
    "        \"\"\"Обучение модели и сохранение на диск\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model = self.create_model(model_type, params)\n",
    "        \n",
    "        if model_type == 'svm':\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            self.scalers[model_name] = scaler\n",
    "        else:\n",
    "            X_scaled = X\n",
    "        \n",
    "        model.fit(X_scaled, y)\n",
    "        \n",
    "        model_path = os.path.join(self.models_dir, f\"{model_name}.pkl\")\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'model': model,\n",
    "                'model_type': model_type,\n",
    "                'params': params\n",
    "            }, f)\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        return training_time\n",
    "    \n",
    "    def load_model(self, model_name: str) -> bool:\n",
    "        \"\"\"Загрузка модели в память\"\"\"\n",
    "        model_path = os.path.join(self.models_dir, f\"{model_name}.pkl\")\n",
    "        \n",
    "        if not os.path.exists(model_path):\n",
    "            return False\n",
    "        \n",
    "        with open(model_path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        self.loaded_models[model_name] = model_data\n",
    "        return True\n",
    "    \n",
    "    def unload_model(self, model_name: str) -> bool:\n",
    "        \"\"\"Выгрузка модели из памяти\"\"\"\n",
    "        if model_name in self.loaded_models:\n",
    "            del self.loaded_models[model_name]\n",
    "            if model_name in self.scalers:\n",
    "                del self.scalers[model_name]\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def predict(self, model_name: str, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Предсказание с помощью загруженной модели\"\"\"\n",
    "        if model_name not in self.loaded_models:\n",
    "            raise ValueError(f\"Модель {model_name} не загружена\")\n",
    "        \n",
    "        model_data = self.loaded_models[model_name]\n",
    "        model = model_data['model']\n",
    "        \n",
    "        if model_name in self.scalers:\n",
    "            X_scaled = self.scalers[model_name].transform(X)\n",
    "        else:\n",
    "            X_scaled = X\n",
    "        \n",
    "        predictions = model.predict(X_scaled)\n",
    "        \n",
    "        probabilities = None\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            probabilities = model.predict_proba(X_scaled)\n",
    "        \n",
    "        return predictions, probabilities\n",
    "    \n",
    "    def delete_model(self, model_name: str) -> bool:\n",
    "        \"\"\"Удаление модели с диска\"\"\"\n",
    "        model_path = os.path.join(self.models_dir, f\"{model_name}.pkl\")\n",
    "        \n",
    "        self.unload_model(model_name)\n",
    "        \n",
    "        if os.path.exists(model_path):\n",
    "            os.remove(model_path)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def delete_all_models(self) -> int:\n",
    "        \"\"\"Удаление всех моделей\"\"\"\n",
    "        count = 0\n",
    "        for filename in os.listdir(self.models_dir):\n",
    "            if filename.endswith('.pkl'):\n",
    "                os.remove(os.path.join(self.models_dir, filename))\n",
    "                count += 1\n",
    "        \n",
    "        self.loaded_models.clear()\n",
    "        self.scalers.clear()\n",
    "        \n",
    "        return count\n",
    "    \n",
    "    def get_loaded_models_count(self) -> int:\n",
    "        \"\"\"Количество загруженных моделей\"\"\"\n",
    "        return len(self.loaded_models)\n",
    "    \n",
    "    def model_exists(self, model_name: str) -> bool:\n",
    "        \"\"\"Проверка существования модели\"\"\"\n",
    "        model_path = os.path.join(self.models_dir, f\"{model_name}.pkl\")\n",
    "        return os.path.exists(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## app/process_manager.py\n",
    "\n",
    "* Реализует класс ProcessManager для управления параллельным обучением моделей\n",
    "* Использует модуль multiprocessing для создания отдельных процессов обучения\n",
    "* Ограничивает количество одновременно обучающихся моделей согласно настройкам CPU\n",
    "* Управляет очередями для обмена данными между процессами\n",
    "* Отслеживает статус выполнения процессов обучения\n",
    "* Предоставляет методы для проверки доступности ресурсов и очистки завершенных процессов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import Process, Queue\n",
    "import time\n",
    "from typing import Dict, Any, Optional\n",
    "import numpy as np\n",
    "\n",
    "class ProcessManager:\n",
    "    \"\"\"Менеджер для управления процессами обучения\"\"\"\n",
    "    \n",
    "    def __init__(self, max_processes: int, models_dir: str):\n",
    "        from app.model_manager import ModelManager\n",
    "        \n",
    "        self.max_processes = max_processes\n",
    "        self.model_manager = ModelManager(models_dir)\n",
    "        self.active_processes: Dict[str, Process] = {}\n",
    "        self.process_queues: Dict[str, Queue] = {}\n",
    "        self.results: Dict[str, Dict[str, Any]] = {}\n",
    "    \n",
    "    def _train_worker(self, queue: Queue, model_name: str, model_type: str,\n",
    "                     X: np.ndarray, y: np.ndarray, params: Dict[str, Any]) -> None:\n",
    "        \"\"\"Рабочая функция для процесса обучения\"\"\"\n",
    "        try:\n",
    "            training_time = self.model_manager.train_model(\n",
    "                model_name, model_type, X, y, params\n",
    "            )\n",
    "            queue.put({\n",
    "                'status': 'success',\n",
    "                'model_name': model_name,\n",
    "                'training_time': training_time\n",
    "            })\n",
    "        except Exception as e:\n",
    "            queue.put({\n",
    "                'status': 'error',\n",
    "                'model_name': model_name,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    def start_training(self, model_name: str, model_type: str,\n",
    "                      X: np.ndarray, y: np.ndarray, params: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Запуск процесса обучения\"\"\"\n",
    "        if len(self.active_processes) >= self.max_processes:\n",
    "            return False\n",
    "        \n",
    "        if self.model_manager.model_exists(model_name):\n",
    "            return False\n",
    "        \n",
    "        queue = Queue()\n",
    "        \n",
    "        process = Process(\n",
    "            target=self._train_worker,\n",
    "            args=(queue, model_name, model_type, X, y, params)\n",
    "        )\n",
    "        \n",
    "        process.start()\n",
    "        self.active_processes[model_name] = process\n",
    "        self.process_queues[model_name] = queue\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def check_training_status(self, model_name: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Проверка статуса обучения\"\"\"\n",
    "        if model_name not in self.active_processes:\n",
    "            return None\n",
    "        \n",
    "        process = self.active_processes[model_name]\n",
    "        queue = self.process_queues[model_name]\n",
    "        \n",
    "        if not process.is_alive():\n",
    "            if not queue.empty():\n",
    "                result = queue.get()\n",
    "                self.results[model_name] = result\n",
    "            \n",
    "            process.join()\n",
    "            del self.active_processes[model_name]\n",
    "            del self.process_queues[model_name]\n",
    "            \n",
    "            if model_name in self.results:\n",
    "                return self.results[model_name]\n",
    "        \n",
    "        return {'status': 'training', 'model_name': model_name}\n",
    "    \n",
    "    def get_active_processes_count(self) -> int:\n",
    "        \"\"\"Количество активных процессов\"\"\"\n",
    "        return len(self.active_processes)\n",
    "    \n",
    "    def can_start_training(self) -> bool:\n",
    "        \"\"\"Можно ли запустить новый процесс\"\"\"\n",
    "        return len(self.active_processes) < self.max_processes\n",
    "    \n",
    "    def cleanup_finished_processes(self):\n",
    "        \"\"\"Очистка завершенных процессов\"\"\"\n",
    "        finished = []\n",
    "        for model_name, process in self.active_processes.items():\n",
    "            if not process.is_alive():\n",
    "                finished.append(model_name)\n",
    "        \n",
    "        for model_name in finished:\n",
    "            process = self.active_processes[model_name]\n",
    "            process.join()\n",
    "            del self.active_processes[model_name]\n",
    "            del self.process_queues[model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## app/main.py\n",
    "\n",
    "* Создает FastAPI приложение с основными эндпоинтами для работы с ML-моделями\n",
    "* Реализует REST API для: обучения моделей (/fit), предсказаний (/predict), загрузки/выгрузки моделей, удаления моделей\n",
    "* Обрабатывает ошибки и граничные случаи (ограничение по CPU, дублирование имен, несуществующие модели)\n",
    "* Интегрирует ModelManager и ProcessManager для управления моделями и процессами\n",
    "* Предоставляет статус сервера и список доступных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException, BackgroundTasks\n",
    "from fastapi.responses import JSONResponse\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "import uvicorn\n",
    "\n",
    "from app.config import settings\n",
    "from app.schemas import (\n",
    "    FitRequest, PredictRequest, ModelConfig,\n",
    "    FitResponse, PredictResponse, StatusResponse\n",
    ")\n",
    "from app.model_manager import ModelManager\n",
    "from app.process_manager import ProcessManager\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"ML Model Training Server\",\n",
    "    description=\"Веб-сервер для обучения и использования ML моделей\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "model_manager = ModelManager(settings.models_dir)\n",
    "process_manager = ProcessManager(\n",
    "    max_processes=settings.cpu_cores - 1,  \n",
    "    models_dir=settings.models_dir\n",
    ")\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    \"\"\"Корневой эндпоинт\"\"\"\n",
    "    return {\n",
    "        \"message\": \"ML Model Training Server\",\n",
    "        \"status\": \"running\",\n",
    "        \"config\": {\n",
    "            \"models_dir\": settings.models_dir,\n",
    "            \"cpu_cores\": settings.cpu_cores,\n",
    "            \"max_loaded_models\": settings.max_loaded_models\n",
    "        }\n",
    "    }\n",
    "\n",
    "@app.get(\"/status\")\n",
    "async def get_status():\n",
    "    \"\"\"Получение статуса сервера\"\"\"\n",
    "    return {\n",
    "        \"active_training_processes\": process_manager.get_active_processes_count(),\n",
    "        \"loaded_models\": model_manager.get_loaded_models_count(),\n",
    "        \"max_loaded_models\": settings.max_loaded_models,\n",
    "        \"can_start_training\": process_manager.can_start_training()\n",
    "    }\n",
    "\n",
    "@app.post(\"/fit\", response_model=FitResponse)\n",
    "async def fit_model(request: FitRequest):\n",
    "    \"\"\"Обучение модели\"\"\"\n",
    "    if not process_manager.can_start_training():\n",
    "        raise HTTPException(\n",
    "            status_code=429,\n",
    "            detail=\"Нет свободных ядер для обучения. Максимум процессов: \"\n",
    "                   f\"{settings.cpu_cores - 1}\"\n",
    "        )\n",
    "    \n",
    "    if model_manager.model_exists(request.model_name):\n",
    "        raise HTTPException(\n",
    "            status_code=400,\n",
    "            detail=f\"Модель с именем '{request.model_name}' уже существует\"\n",
    "        )\n",
    "    \n",
    "    if request.model_type not in ['logreg', 'rf', 'svm']:\n",
    "        raise HTTPException(\n",
    "            status_code=400,\n",
    "            detail=f\"Неподдерживаемый тип модели. Доступные: logreg, rf, svm\"\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        X = np.array(request.features)\n",
    "        y = np.array(request.labels)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=400,\n",
    "            detail=f\"Ошибка преобразования данных: {str(e)}\"\n",
    "        )\n",
    "    \n",
    "    success = process_manager.start_training(\n",
    "        request.model_name,\n",
    "        request.model_type,\n",
    "        X, y,\n",
    "        request.params\n",
    "    )\n",
    "    \n",
    "    if not success:\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=\"Не удалось запустить процесс обучения\"\n",
    "        )\n",
    "    \n",
    "    return FitResponse(\n",
    "        status=\"started\",\n",
    "        model_name=request.model_name,\n",
    "        message=f\"Обучение модели '{request.model_name}' запущено\"\n",
    "    )\n",
    "\n",
    "@app.get(\"/fit/{model_name}/status\")\n",
    "async def get_fit_status(model_name: str):\n",
    "    \"\"\"Проверка статуса обучения модели\"\"\"\n",
    "    status = process_manager.check_training_status(model_name)\n",
    "    \n",
    "    if status is None:\n",
    "        if model_manager.model_exists(model_name):\n",
    "            return {\n",
    "                \"status\": \"completed\",\n",
    "                \"model_name\": model_name,\n",
    "                \"message\": \"Модель уже обучена\"\n",
    "            }\n",
    "        else:\n",
    "            raise HTTPException(\n",
    "                status_code=404,\n",
    "                detail=f\"Обучение модели '{model_name}' не найдено\"\n",
    "            )\n",
    "    \n",
    "    if status['status'] == 'error':\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=f\"Ошибка при обучении: {status.get('error', 'Unknown error')}\"\n",
    "        )\n",
    "    \n",
    "    return status\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictResponse)\n",
    "async def predict(request: PredictRequest):\n",
    "    \"\"\"Предсказание с помощью обученной модели\"\"\"\n",
    "    if request.model_name not in model_manager.loaded_models:\n",
    "        if not model_manager.load_model(request.model_name):\n",
    "            raise HTTPException(\n",
    "                status_code=404,\n",
    "                detail=f\"Модель '{request.model_name}' не найдена\"\n",
    "            )\n",
    "    \n",
    "    if model_manager.get_loaded_models_count() > settings.max_loaded_models:\n",
    "        raise HTTPException(\n",
    "            status_code=429,\n",
    "            detail=f\"Превышен лимит загруженных моделей: {settings.max_loaded_models}\"\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        X = np.array(request.features)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=400,\n",
    "            detail=f\"Ошибка преобразования данных: {str(e)}\"\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        predictions, probabilities = model_manager.predict(request.model_name, X)\n",
    "        \n",
    "        prob_list = None\n",
    "        if probabilities is not None:\n",
    "            prob_list = probabilities.tolist()\n",
    "        \n",
    "        return PredictResponse(\n",
    "            status=\"success\",\n",
    "            predictions=predictions.tolist(),\n",
    "            probabilities=prob_list\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=f\"Ошибка при предсказании: {str(e)}\"\n",
    "        )\n",
    "\n",
    "@app.post(\"/load\", response_model=StatusResponse)\n",
    "async def load_model(config: ModelConfig):\n",
    "    \"\"\"Загрузка модели в память\"\"\"\n",
    "    if not model_manager.model_exists(config.model_name):\n",
    "        raise HTTPException(\n",
    "            status_code=404,\n",
    "            detail=f\"Модель '{config.model_name}' не найдена\"\n",
    "        )\n",
    "    \n",
    "    if model_manager.get_loaded_models_count() >= settings.max_loaded_models:\n",
    "        raise HTTPException(\n",
    "            status_code=429,\n",
    "            detail=f\"Превышен лимит загруженных моделей: {settings.max_loaded_models}\"\n",
    "        )\n",
    "    \n",
    "    success = model_manager.load_model(config.model_name)\n",
    "    \n",
    "    if not success:\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=f\"Не удалось загрузить модель '{config.model_name}'\"\n",
    "        )\n",
    "    \n",
    "    return StatusResponse(\n",
    "        status=\"success\",\n",
    "        message=f\"Модель '{config.model_name}' загружена в память\"\n",
    "    )\n",
    "\n",
    "@app.post(\"/unload\", response_model=StatusResponse)\n",
    "async def unload_model(config: ModelConfig):\n",
    "    \"\"\"Выгрузка модели из памяти\"\"\"\n",
    "    success = model_manager.unload_model(config.model_name)\n",
    "    \n",
    "    if not success:\n",
    "        raise HTTPException(\n",
    "            status_code=404,\n",
    "            detail=f\"Модель '{config.model_name}' не загружена в память\"\n",
    "        )\n",
    "    \n",
    "    return StatusResponse(\n",
    "        status=\"success\",\n",
    "        message=f\"Модель '{config.model_name}' выгружена из памяти\"\n",
    "    )\n",
    "\n",
    "@app.delete(\"/remove\", response_model=StatusResponse)\n",
    "async def remove_model(config: ModelConfig):\n",
    "    \"\"\"Удаление модели с диска\"\"\"\n",
    "    model_manager.unload_model(config.model_name)\n",
    "    \n",
    "    success = model_manager.delete_model(config.model_name)\n",
    "    \n",
    "    if not success:\n",
    "        raise HTTPException(\n",
    "            status_code=404,\n",
    "            detail=f\"Модель '{config.model_name}' не найдена на диске\"\n",
    "        )\n",
    "    \n",
    "    return StatusResponse(\n",
    "        status=\"success\",\n",
    "        message=f\"Модель '{config.model_name}' удалена с диска\"\n",
    "    )\n",
    "\n",
    "@app.delete(\"/remove_all\", response_model=StatusResponse)\n",
    "async def remove_all_models():\n",
    "    \"\"\"Удаление всех моделей\"\"\"\n",
    "    count = model_manager.delete_all_models()\n",
    "    \n",
    "    return StatusResponse(\n",
    "        status=\"success\",\n",
    "        message=f\"Удалено {count} моделей\",\n",
    "        details={\"deleted_count\": count}\n",
    "    )\n",
    "\n",
    "@app.get(\"/models\")\n",
    "async def list_models():\n",
    "    \"\"\"Список всех моделей\"\"\"\n",
    "    import os\n",
    "    models = []\n",
    "    \n",
    "    for filename in os.listdir(settings.models_dir):\n",
    "        if filename.endswith('.pkl'):\n",
    "            model_name = filename[:-4]  # Убираем .pkl\n",
    "            models.append({\n",
    "                \"name\": model_name,\n",
    "                \"loaded\": model_name in model_manager.loaded_models\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        \"models\": models,\n",
    "        \"count\": len(models)\n",
    "    }\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    \"\"\"Действия при запуске сервера\"\"\"\n",
    "    import os\n",
    "    os.makedirs(settings.models_dir, exist_ok=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(\n",
    "        \"app.main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        reload=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requirements.txt\n",
    "\n",
    "* Содержит список всех Python-зависимостей проекта с указанием версий\n",
    "* FastAPI и Uvicorn для веб-сервера\n",
    "* Pydantic для валидации данных\n",
    "* Scikit-learn для ML-моделей\n",
    "* NumPy и Pandas для работы с данными\n",
    "* Requests и Aiohttp для клиентской части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastapi==0.104.1\n",
    "uvicorn[standard]==0.24.0\n",
    "pydantic==2.5.0\n",
    "pydantic-settings==2.1.0\n",
    "scikit-learn==1.3.2\n",
    "numpy==1.24.3\n",
    "pandas==2.1.4\n",
    "requests==2.31.0\n",
    "aiohttp==3.9.1\n",
    "python-multipart==0.0.6\n",
    "python-dotenv==1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerfile \n",
    "\n",
    "* Определяет Docker-образ на основе Python 3.9 slim\n",
    "* Устанавливает зависимости из requirements.txt\n",
    "* Копирует исходный код приложения\n",
    "* Создает директорию для сохранения моделей\n",
    "* Открывает порт 8000 для доступа к API\n",
    "* Запускает сервер Uvicorn при старте контейнера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "RUN mkdir -p saved_models\n",
    "\n",
    "EXPOSE 8000\n",
    "\n",
    "CMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## docker-compose.yml\n",
    "\n",
    "* Определяет сервис ml-server для запуска приложения\n",
    "* Пробрасывает порт 8000 из контейнера на хост\n",
    "* Монтирует директории для сохранения моделей и данных\n",
    "* Загружает переменные окружения из файла .env\n",
    "* Устанавливает параметры по умолчанию\n",
    "* Настраивает автоматический перезапуск при падении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "services:\n",
    "  ml-server:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    volumes:\n",
    "      - ./saved_models:/app/saved_models\n",
    "      - ./data:/app/data\n",
    "    env_file:\n",
    "      - .env\n",
    "    environment:\n",
    "      - MODELS_DIR=/app/saved_models\n",
    "      - CPU_CORES=4\n",
    "      - MAX_LOADED_MODELS=3\n",
    "    restart: unless-stopped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
